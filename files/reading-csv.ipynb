{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4bd330",
   "metadata": {},
   "source": [
    "#### **DataFrames y Series**\n",
    "\n",
    "- **DataFrames** -> pd.DataFrame()\n",
    "  - Estructura de datos bidimensional (varias columnas) en pandas.\n",
    "  - Cada columna puede tener un tipo de dato diferente (números, cadenas, fechas, etc.).\n",
    "  - Se pueden crear a partir de diccionarios, listas, archivos CSV, entre otros\n",
    "\n",
    "- **Series** -> pd.Series()\n",
    "  - Estructura de datos unidimensional (una sola columna) en pandas.\n",
    "  - Similar a una columna de un DataFrame.\n",
    "  - Puede contener cualquier tipo de dato y tiene un índice asociado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197cb5e",
   "metadata": {},
   "source": [
    "#### **Operaciones con DataFrames** - Modificación de datos\n",
    "\n",
    "Importamos pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797d206",
   "metadata": {},
   "source": [
    "#### **Reading CSV with Pandas**\n",
    "\n",
    "- CSV is very heavy to work with.\n",
    "- There are other file formats that are more efficient, but CSV is very common and easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../data/results.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26591f4c",
   "metadata": {},
   "source": [
    "#### **Reading PARQUET with Pandas**\n",
    "\n",
    "- PARQUET is a columnar storage file format that is more efficient than CSV.\n",
    "- It is optimized for performance and storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"../data/results.parquet\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4935268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a CSV - no optimo\n",
    "data_csv = data.to_csv(\"data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb243d",
   "metadata": {},
   "source": [
    "#### SAMPLE - Obtener una muestra aleatoria de un DataFrame\n",
    "- sample() permite obtener una muestra aleatoria de un DataFrame.\n",
    "  - n: indicar el numero de filas a seleccionar.\n",
    "  - frac: indicar la fraccion de filas a seleccionar (no se puede usar junto a n).\n",
    "  - random_state: indicar el valor para asegurar reproducibilidad en la seleccion aleatoria.\n",
    "  - replace: si es True, permite seleccionar la misma fila mas de una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = data.sample(random_state=10, frac=0.001, replace=False)\n",
    "\n",
    "random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fc9b7",
   "metadata": {},
   "source": [
    "#### LOC (location) - Accesing data from file\n",
    "\n",
    "- loc permite acceder a filas y columnas por etiquetas (nombres de filas y columnas)\n",
    "- iloc permite acceder a filas y columnas por indices (numeros de filas y columnas) solamente\n",
    "\n",
    "#### IAT (Index At) - Acceding a single row from a file\n",
    "\n",
    "- iat permite acceder a un solo valor de una fila y columna especifica por indice (numero de fila y numero de columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d329933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la fila 300000 (index) hasta la 300003 (inclusive)\n",
    "data.loc[300000:300003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la fila 0, 5 y 10\n",
    "data.loc[[0, 5, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a284b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a las primeras 10 filas\n",
    "data.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder desde la fila 10 hasta el final\n",
    "data.loc[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b086966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a todas las filas solo de la columna \"discipline\"\n",
    "data.loc[510:530, \"discipline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a las primeras 10 filas de las columnas \"discipline\" y \"year\"\n",
    "data.loc[:9, [\"discipline\", \"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a las primeras 10 filas de las columnas en las posiciones 2 y 0\n",
    "data.iloc[:10, [2, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas por año mayor a 2020 mostrando solo 2 columnas\n",
    "data.loc[data[\"year\"] > 2020, [\"year\", \"as\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas por año mayor a 2018 y disciplina \"Tennis\" mostrando solo 2 columnas\n",
    "data.loc[(data[\"year\"] > 2018) & (data[\"discipline\"] == \"Tennis\"), [\"year\", \"discipline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67db0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columa \"age\" \n",
    "data[\"age\"] = 2026 - data[\"year\"]\n",
    "data.loc[:50, [\"year\", \"age\"]].sort_values(by=\"age\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generando un DataFrame de 10 filas ordenadas por la columna \"place\" en orden descendente\n",
    "data_piece = data.sort_values(by=[\"place\"], ascending=False).sample(n=10)\n",
    "\n",
    "# Reemplazando los valores NaN en la columna \"place\" por 0\n",
    "data_piece.loc[data_piece[\"place\"].isna(), \"place\"] = 0\n",
    "\n",
    "# Accediendo a la columna \"place\" del DataFrame generado\n",
    "data_piece.loc[:, [\"as\", \"place\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar el valor de la columna \"year\" en las primeras 10 filas a 2000\n",
    "# Esto modifica el dataframe original\n",
    "data.loc[:10, [\"year\"]] = 2000\n",
    "data.loc[:15, [\"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6fed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al valor de la fila 0 y columna 0\n",
    "data.iat[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe35700",
   "metadata": {},
   "source": [
    "#### sort_values() - Sort DataFrame by the values of one or more columns.\n",
    "\n",
    "- sort_values() permite ordenar un DataFrame por los valores de una o mas columnas.\n",
    "- Por defecto, ordena en orden ascendente (ascending=True).\n",
    "  - Se puede especificar el parametro ascending=False para ordenar en orden descendente. Se puede usar una lista de booleanos para ordenar diferentes columnas en diferentes ordenes.\n",
    "  - Se puede especificar el parametro by para indicar las columnas por las que se quiere ordenar.\n",
    "  - Se puede especificar el parametro inplace=True para modificar el DataFrame original en lugar de crear una copia ordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar el DataFrama por las columnas \"year\" (descendente) y \"as\" (ascendente) sin modificar el archivo\n",
    "data_sorted = data.sort_values(by=[\"year\", \"as\"], ascending=[False, True], inplace=False)\n",
    "data_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96438310",
   "metadata": {},
   "source": [
    "#### Iterar sobre filas de un DataFrame\n",
    "\n",
    "- No es recomendable iterar sobre las filas de un DataFrame, ya que es ineficiente y va en contra del paradigma de pandas.\n",
    "- Se puede usar el metodo iterrows() para iterar sobre las filas de un DataFrame.\n",
    "  - Cada fila se devuelve como una tupla que contiene el indice de la fila y una Serie con los datos de la fila.\n",
    "- Se puede usar el metodo itertuples() para iterar sobre las filas de un DataFrame.\n",
    "  - Cada fila se devuelve como una tupla nombrada, donde los nombres de los campos son los nombres de las columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre las primeras 15 filas de un DataFrame\n",
    "for index, row in data.head(15).iterrows():\n",
    "    print(f\"Index: {index}, Year: {row['year']}, Discipline: {row['discipline']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d1ee1",
   "metadata": {},
   "source": [
    "#### DROP - Eliminar filas o columnas de un DataFrame\n",
    "\n",
    "- drop() permite eliminar filas o columnas de un DataFrame.\n",
    "  - Se puede especificar columns=[...] para eliminar columnas por nombre.\n",
    "  - Se puede especificar index=[...] para eliminar filas por indice.\n",
    "  - Se puede especificar el parametro axis=0 para eliminar filas (por defecto) o axis=1 para eliminar columnas.\n",
    "  - Se puede especificar el parametro inplace=True para modificar el DataFrame original en lugar de crear una copia modificada.\n",
    "  - Se puede especificar el parametro errors='ignore' para evitar errores si la fila o columna no existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbe876",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_parquet(\"../data/results.parquet\")\n",
    "new_data.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna \"tied\" sin modificar el DataFrame original\n",
    "new_data.drop(columns=[\"tied\"], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data[\"place\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a96c4",
   "metadata": {},
   "source": [
    "#### Copy() - Crear una copia de un DataFrame\n",
    "\n",
    "- Pandas utiliza referencias a los datos originales para optimizar el uso de memoria.\n",
    "- Para crear una copia independiente de un DataFrame, se puede usar el metodo copy().\n",
    "- Esto es util cuando se quiere modificar un DataFrame sin afectar al original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a945c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mismo espacio de memoria\n",
    "new_data = data\n",
    "\n",
    "# Eliminar la columna \"year\" modificando el DataFrame original\n",
    "new_data.drop(columns=[\"year\"], inplace=True)\n",
    "\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferente espacio de memoria\n",
    "new_data = data.copy()\n",
    "\n",
    "# Eliminar la columna \"year\" sin modificar el DataFrame original\n",
    "new_data.drop(columns=[\"year\"], inplace=True)\n",
    "\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f551b04",
   "metadata": {},
   "source": [
    "#### Rename - Renombrar filas o columnas de un DataFrame\n",
    "\n",
    "- rename() permite renombrar filas o columnas de un DataFrame.\n",
    "  - Se puede especificar el parametro columns={...} para renombrar columnas por nombre.\n",
    "  - Se puede especificar el parametro index={...} para renombrar filas por indice.\n",
    "  - Se puede especificar el parametro inplace=True para modificar el DataFrame original en lugar de crear una copia modificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna \"as\" a \"name\" y \"discipline\" a \"sport\" sin modificar el DataFrame original\n",
    "new_data.rename(columns={\"as\": \"name\", \"discipline\": \"sport\"}, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824f2c1",
   "metadata": {},
   "source": [
    "#### to_datetime y dt - Acceder a propiedades de fechas en una columna datetime\n",
    "\n",
    "- to_datetime() permite convertir una columna a tipo datetime.\n",
    "  - format: especifica el formato de la fecha en la columna original.\n",
    "  - errors: especifica como manejar errores en la conversion ('raise', 'coerce', 'ignore').\n",
    "  - utc: si es True, convierte las fechas a UTC.\n",
    "- dt permite acceder a propiedades de fechas en una columna datetime.\n",
    "  - Se puede acceder a propiedades como year, month, day, hour, minute, second, weekday, etc.\n",
    "  - Se puede usar para crear nuevas columnas basadas en propiedades de fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c22502",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_data = pd.read_csv(\"../data/bios.csv\")\n",
    "bios_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"born_date\" a tipo datetime\n",
    "bios_data[\"born_date\"] = pd.to_datetime(bios_data[\"born_date\"])\n",
    "# bios_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7961f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al año\n",
    "bios_data[\"born_year\"] = bios_data[\"born_date\"].dt.year\n",
    "\n",
    "# Acceder al mes\n",
    "bios_data[\"born_month\"] = bios_data[\"born_date\"].dt.month\n",
    "\n",
    "# Acceder al día\n",
    "bios_data[\"born_day\"] = bios_data[\"born_date\"].dt.day\n",
    "\n",
    "bios_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754646c",
   "metadata": {},
   "source": [
    "#### Apply - Aplicar una funcion a lo largo de un eje de un DataFrame\n",
    "\n",
    "- apply() permite aplicar una funcion a lo largo de un eje de un DataFrame (filas o columnas).\n",
    "  - axis=0 aplica la funcion a cada columna (por defecto).\n",
    "  - axis=1 aplica la funcion a cada fila.\n",
    "  - La funcion puede ser una funcion definida por el usuario o una funcion lambda.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna \"weight_class\" basada en la columna \"weight_kg\" usando apply() y una funcion lambda\n",
    "bios_data[\"weight_class\"] = bios_data[\"weight_kg\"].apply(lambda x: \"Heavyweight\" if x >= 100 else (\"Normalweight\" \n",
    "if x >= 70 else \"Lightweight\"))\n",
    "\n",
    "bios_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna \"height_class\" basada en la columna \"height_cm\" usando apply() y una funcion definida por el usuario\n",
    "def height_class(row):\n",
    "  if row[\"height_cm\"] >= 190:\n",
    "    return \"Tall\"\n",
    "  elif row[\"height_cm\"] >= 170 and row[\"height_cm\"] < 190:\n",
    "    return \"Average\"\n",
    "  else :\n",
    "    return \"Short\"\n",
    "\n",
    "# Aplicar la funcion a lo largo de las filas (axis=1)\n",
    "bios_data[\"height_class\"] = bios_data.apply(height_class, axis=1)\n",
    "\n",
    "bios_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb477a",
   "metadata": {},
   "source": [
    "#### merge - Combinar dos DataFrames basados en una o mas columnas clave\n",
    "\n",
    "- merge() permite combinar dos DataFrames basados en una o mas columnas clave.\n",
    "  - on: especifica las columnas clave comunes en ambos DataFrames.\n",
    "  - left_on: especifica las columnas clave en el DataFrame izquierdo.\n",
    "  - right_on: especifica las columnas clave en el DataFrame derecho.\n",
    "  - how: especifica el tipo de combinacion ('inner', 'outer', 'left', 'right').\n",
    "    - 'inner': solo filas con claves coincidentes en ambos DataFrames.\n",
    "    - 'outer': todas las filas de ambos DataFrames, con NaN donde no hay coincidencia.\n",
    "    - 'left': todas las filas del DataFrame izquierdo, con NaN donde no hay coincidencia en el derecho.\n",
    "    - 'right': todas las filas del DataFrame derecho, con NaN donde no hay coincidencia en el izquierdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noc_regions = pd.read_csv(\"../data/noc_regions.csv\")\n",
    "noc_regions.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e82a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noc_reduced = noc_regions[[\"region\", \"NOC\"]]\n",
    "new_bios_data = pd.merge(bios_data, noc_reduced, left_on=\"born_country\", right_on=\"NOC\", how=\"inner\")\n",
    "new_bios_data.drop(columns=[\"NOC_y\"], inplace=True)\n",
    "new_bios_data.rename(columns={\"region\": \"born_country_name\", \"NOC_x\": \"NOC\"}, inplace=True)\n",
    "new_bios_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78702769",
   "metadata": {},
   "source": [
    "#### **Useful functions**\n",
    "\n",
    "- **df.mean()** calcula el promedio de los valores numéricos de una columna (ignora valores NaN).\n",
    "  - _skipna:_ si es True (por defecto), ignora los valores NaN en el calculo.\n",
    "\n",
    "- **df.median()** calcula la mediana de los valores numéricos.\n",
    "\n",
    "- **df.isna()** devuelve el DataFrame con valores booleanos indicando si el valor es NaN.\n",
    "\n",
    "- **df.notna()** devuelve el DataFrame con valores booleanos indicando si el valor no es NaN.\n",
    "\n",
    "- **df.dropna()** elimina filas o columnas con valores NaN.\n",
    "  - _axis:_ especifica si eliminar filas (0) o columnas (1).\n",
    "  - _how:_ 'any' elimina si hay al menos un NaN, 'all' elimina solo si todos son NaN.\n",
    "  - _thresh:_ numero minimo de valores no-NaN requeridos para mantener la fila/columna.\n",
    "  - _inplace:_ si es True, modifica el DataFrame original en lugar de crear una copia modificada.\n",
    "\n",
    "- **df.sum()** calcula la suma de los valores numéricos de una columna.\n",
    "\n",
    "- **df.value_counts()** cuenta la frecuencia de valores únicos en una columna.\n",
    "\n",
    "- **df.unique()** devuelve los valores únicos en una columna.\n",
    "\n",
    "- **interpolate()** permite rellenar valores NaN mediante interpolación (patrones de valores).\n",
    "  - _method:_ especifica el metodo de interpolacion ('linear', 'time', 'index', 'values', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic').\n",
    "  - _limit:_ especifica el numero maximo de valores NaN a rellenar.\n",
    "  - _inplace:_ si es True, modifica el DataFrame original en lugar de crear una copia modificada.\n",
    "  - _axis:_ especifica el eje a lo largo del cual se aplica la interpolacion (0 para filas, 1 para columnas).\n",
    "\n",
    "- **df.fillna()** permite rellenar valores NaN con un valor especifico\n",
    "  - _value:_ el valor con el que se rellenaran los NaN.\n",
    "  - _inplace:_ si es True, modifica el DataFrame original en lugar de crear una copia modificada.\n",
    "\n",
    "- **pd.groupby()** permite agrupar un DataFrame por una o mas columnas y aplicar funciones de agregacion.\n",
    "  - _by:_ especifica las columnas por las que se quiere agrupar.\n",
    "  - _aggfunc:_ especifica la funcion de agregacion a aplicar (por ejemplo, 'mean', 'sum', 'count', etc.).\n",
    "\n",
    "- **df.agg()** permite aplicar una o mas funciones de agregacion a un DataFrame agrupado.\n",
    "  - Se puede pasar un objeto diccionario para aplicar diferentes funciones a diferentes columnas.\n",
    "    - _Ejemplo_: df.agg({'col1': 'mean', 'col2': ['sum', 'max']})\n",
    "  - _func:_ especifica la funcion o lista de funciones de agregacion a aplicar.\n",
    "  - _axis:_ especifica el eje a lo largo del cual se aplica la agregacion (0 para filas, 1 para columnas).\n",
    "\n",
    "- **df.pivot()** permite reorganizar un DataFrame creando una tabla pivote.\n",
    "  - _index:_ especifica las columnas que se utilizaran como indice (filas) en la tabla pivote.\n",
    "  - _columns:_ especifica las columnas que se utilizaran como columnas en la tabla pivote.\n",
    "  - _values:_ especifica las columnas cuyos valores se agregaran en la tabla pivote.\n",
    "  - _aggfunc:_ especifica la funcion de agregacion a aplicar a los valores (por defecto es 'mean').\n",
    "\n",
    "- **df.shift()** permite desplazar los valores de un DataFrame hacia arriba o hacia abajo.\n",
    "  - _periods:_ especifica el numero de periodos a desplazar (positivo -> abajo, negativo -> arriba).\n",
    "  - _axis:_ especifica el eje a lo largo del cual se aplica el desplazamiento (0 para filas, 1 para columnas).\n",
    "\n",
    "- **df.cumsum()** calcula la suma acumulativa de los valores a lo largo de un eje.\n",
    "  - _axis:_ especifica el eje a lo largo del cual se aplica la suma acumulativa (0 para filas, 1 para columnas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv(\"../warmup-data/coffee.csv\")\n",
    "bios = pd.read_csv(\"../data/bios.csv\")\n",
    "results = pd.read_parquet(\"../data/results.parquet\")\n",
    "bios[\"born_date\"] = pd.to_datetime(bios[\"born_date\"])\n",
    "bios[\"died_date\"] = pd.to_datetime(bios[\"died_date\"])\n",
    "coffee[\"price\"] = coffee[\"Coffee Type\"].map({\"Espresso\": 3.0, \"Latte\": 4.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar las filas donde el tipo de café es \"Espresso\"\n",
    "coffee_espresso = coffee.loc[coffee[\"Coffee Type\"] == \"Espresso\"]\n",
    "\n",
    "# Calcular el promedio de la columna \"Units Sold\" para los cafés tipo \"Espresso\"\n",
    "coffee_espresso[\"Units Sold\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"Units Sold\" con el promedio de la columna\n",
    "coffee.fillna(coffee[\"Units Sold\"].mean(), inplace=True)\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"Units Sold\" usando interpolación\n",
    "coffee[\"Units Sold\"] = coffee[\"Units Sold\"].fillna(coffee[\"Units Sold\"].interpolate())\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener cuantos cafes se vendieron por dia (ordenado numericamente)\n",
    "coffee[\"Day\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las personas que nacieron en USA\n",
    "usa_bios = bios[bios[\"born_country\"] == \"USA\"]\n",
    "\n",
    "# Calculamos el promedio de la altura en cm redondeado a 2 decimales\n",
    "usa_bios[\"height_cm\"].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"height_cm\" usando interpolación lineal\n",
    "bios[\"height_cm\"].fillna(bios[\"height_cm\"].interpolate(), inplace=True)\n",
    "\n",
    "# Calcular el promedio de altura por país de nacimiento, redondeado a 2 decimales, y mostrar una muestra aleatoria de 5 países\n",
    "bios.groupby([\"born_country\"])[\"height_cm\"].mean().round(2).sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99480683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"weight_kg\" usando interpolación lineal\n",
    "bios[\"weight_kg\"].fillna(bios[\"weight_kg\"].interpolate(), inplace=True)\n",
    "\n",
    "# Calcular el promedio de peso por NOC para las personas nacidas antes del 2000, redondeado a 2 decimales\n",
    "bios[bios[\"born_date\"].dt.year < 2000].groupby(\"NOC\")[\"weight_kg\"].mean().round(2).sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d521b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una tabla pivote con los días como índice, los tipos de café como columnas y las unidades vendidas como valores\n",
    "coffee[\"Units Sold\"] = coffee[\"Units Sold\"].fillna(coffee[\"Units Sold\"].interpolate()).round(2)\n",
    "pivot = coffee.pivot(columns=\"Coffee Type\", index=\"Day\", values=\"Units Sold\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los años, meses y días de fallecimiento y contamos las ocurrencias\n",
    "bios[\"year_died\"] = bios[\"died_date\"].dt.year\n",
    "bios[\"month_died\"] = bios[\"died_date\"].dt.month\n",
    "bios[\"day_died\"] = bios[\"died_date\"].dt.day\n",
    "\n",
    "# Contar las ocurrencias de fallecimientos por fecha y mostrar los 10 días con menos fallecimientos\n",
    "bios.groupby([\"year_died\", \"month_died\", \"day_died\"])[\"name\"].count().reset_index(name=\"count\").sort_values(by=\"count\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d12ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"Units Sold\" usando interpolación lineal y redondear a 2 decimales\n",
    "coffee[\"Units Sold\"] = coffee[\"Units Sold\"].fillna(coffee[\"Units Sold\"].interpolate()).round(2)\n",
    "\n",
    "# Calcular los ingresos totales por tipo de café, asumiendo que el precio por unidad es: Espresso = $3.0, Latte = $4.0\n",
    "coffee[\"revenue\"] = coffee[\"Units Sold\"] * coffee[\"price\"]\n",
    "\n",
    "# Mover los ingresos 2 filas hacia abajo para visualizar mejor la diferencia de revenue entre dias\n",
    "coffee[\"yesterday_revenue\"] = coffee[\"revenue\"].shift(2)\n",
    "\n",
    "# Calcular la diferencia de ingresos entre el día actual y el día anterior\n",
    "coffee[\"difference_revenue\"] = coffee[\"revenue\"] - coffee[\"yesterday_revenue\"]\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN en la columna \"born_date\" usando interpolación lineal\n",
    "bios[\"born_date\"] = bios[\"born_date\"].fillna(bios[\"born_date\"].interpolate())\n",
    "\n",
    "# Contar los 10 días del mes con más nacimientos\n",
    "bios[\"born_date\"].dt.day.value_counts().head(10).reset_index(name=\"count\").rename(columns={\"born_date\": \"day\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066de684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna \"total_revenue\" que contenga la suma acumulativa de los ingresos diarios\n",
    "\n",
    "coffee[\"Units Sold\"] = coffee[\"Units Sold\"].fillna(coffee[\"Units Sold\"].interpolate()).round(2)\n",
    "\n",
    "coffee[\"revenue\"] = coffee[\"Units Sold\"] * coffee[\"price\"]\n",
    "\n",
    "coffee[\"total_revenue\"] = coffee[\"revenue\"].cumsum()\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee[\"Units Sold\"] = coffee[\"Units Sold\"].fillna(coffee[\"Units Sold\"].interpolate()).round(2)\n",
    "coffee[\"revenue\"] = coffee[\"Units Sold\"] * coffee[\"price\"]\n",
    "\n",
    "espresso_mask = coffee[\"Coffee Type\"] == \"Espresso\"\n",
    "latte_mask = coffee[\"Coffee Type\"] == \"Latte\"\n",
    "\n",
    "coffee[\"espresso_revenue\"] = coffee[\"revenue\"].where(espresso_mask).cumsum().ffill()\n",
    "coffee[\"latte_revenue\"] = coffee[\"revenue\"].where(latte_mask).cumsum().ffill()\n",
    "\n",
    "coffee[\"espresso_units_sold\"] = coffee[\"Units Sold\"].where(espresso_mask).cumsum().ffill()\n",
    "coffee[\"latte_units_sold\"] = coffee[\"Units Sold\"].where(latte_mask).cumsum().ffill()\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[(bios[\"born_region\"] == \"New Hampshire\") | (bios[\"born_city\"] == \"San Francisco\")][[\"name\", \"born_region\", \"born_city\"]].sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
